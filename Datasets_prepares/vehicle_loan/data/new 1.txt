# load useful libraries
library(pacman)
library(tidyverse)
library(skimr)
library(dplyr)
library(caret)
library(pROC)
library(recipes) # could also load the tidymodels package
library(corrplot)
library(lubridate)
library(data.table) # data mgmt
library(gtools) # combination
library(ggplot2) # graphics
library(plotly) # interactive graphics
library(lsr)
library(mltools)
library(labelled)

#seed for replication
set.seed(7)

# set up so that all variables of tibbles are printed
options(dplyr.width = Inf)

#make the working directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
list.files('./data')

datainput = read_delim('./data/train2.csv', col_names = TRUE, delim = ',')
colnames <- names(datainput)

#display information
names(datainput)





###--------------------------------------------------------###
###----------------- Analyse of correlation ---------------###
datainputreduced <- datainput  %>%
  select (ltv,
          Date.of.Birth,
          State_ID,
          branch_id,
          supplier_id,
          Employment.Type,
          VoterID_flag,
          asset_cost,
          SEC.ACTIVE.ACCTS,
          disbursed_amount,
          PERFORM_CNS.SCORE.DESCRIPTION,
          DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS,
          loan_default,
          SEC.NO.OF.ACCTS,
          PRI.CURRENT.BALANCE,
          PRI.ACTIVE.ACCTS) %>%
  mutate(replace_na(datainput$Employment.Type)) %>%
  mutate(State_ID =  as.factor(State_ID)) %>%
  mutate(branch_id =  as.factor(branch_id)) %>%
  mutate(supplier_id =  as.factor(supplier_id)) %>%
  mutate(VoterID_flag =  as.factor(VoterID_flag)) 


datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in% 
                                                 c("C-Very Low Risk", "A-Very Low Risk", "B-Very Low Risk","D-Very Low Risk","F-Low Risk","E-Low Risk","G-Low Risk")] <- "Low"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in% 
                                                 c("H-Medium Risk", "I-Medium Risk")] <- "Medium"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in% 
                                                 c("J-High Risk", "K-High Risk","L-Very High Risk", "M-Very High Risk")] <- "High"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in% 
                                                 c("Not Scored: More than 50 active Accounts found", "Not Scored: Only a Guarantor",
                                                   "Not Scored: Not Enough Info available on the customer", "Not Scored: No Activity seen on the customer (Inactive)",
                                                   "Not Scored: No Updates available in last 36 months", "Not Scored: Sufficient History Not Available",
                                                   "No Bureau History Available")] <- "Not Scored"
thisyear = year(Sys.Date())
datainputreduced <- datainputreduced %>%
  mutate(NbrYear = thisyear-year(dmy(Date.of.Birth))) 
datainputreduced <- datainputreduced %>%
  mutate(NbrYearRelation = 12*(thisyear-year(dmy(Date.of.Birth)) + month(dmy(Date.of.Birth)))) 

partition(skim(datainputreduced))

##Convert as modal


##Analyse univariée
hist(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour", 
     xlab = "Heures", ylab = "Effectif")
boxplot(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour", 
        ylab = "Heures")

##split
# Resulting bins have an equal number of observations in each group
datainputreduced[, "wt2"] <- bin_data(datainputreduced$NbrYear, bins=3, binType = "quantile")

#creating indices
trainIndex <- createDataPartition(datainputreduced$loan_default,p=0.2,list=FALSE)

#splitting data into training/testing data using the trainIndex object
training1_TRAIN <- datainputreduced[trainIndex,] #training data (75% of data)
training1_TEST <- datainputreduced[-trainIndex,] #testing data (25% of data)


var_simple_glm = reformulate(termlabels = c("ltv", "State_ID", "branch_id",  "supplier_id", "Employment.Type", "VoterID_flag", "asset_cost", "SEC.ACTIVE.ACCTS",
  "PERFORM_CNS.SCORE.DESCRIPTION", "DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS", "SEC.NO.OF.ACCTS",
  "PRI.CURRENT.BALANCE", "PRI.ACTIVE.ACCTS", "NbrYear", "NbrYearRelation"), 
  response = "loan_default")

var_simple_glm = reformulate(termlabels = c("ltv",
                                            "State_ID",
                                            "branch_id",
                                            "supplier_id",
                                            "Employment.Type",
                                            "VoterID_flag",
                                            "asset_cost",
                                            "SEC.ACTIVE.ACCTS",
                                            "PERFORM_CNS.SCORE.DESCRIPTION",
                                            "DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS",
                                            "PRI.ACTIVE.ACCTS",
                                            "SEC.NO.OF.ACCTS",
                                            "NbrYear",
                                            "NbrYearRelation"),

                             response = "loan_default")

simple_logit_model = glm(var_simple_glm, data = training1_TRAIN , family = binomial(link = "logit"))



training1_TEST$Score = predict(simple_logit_model, newdata = training1_TEST, type = "response")
test_roc_simple = roc(training1_TEST$loan_default ~ training1_TEST$Score, plot = TRUE, print.auc = TRUE)

# summary(simple_logit_model) # display results
# exp(coef(simple_logit_model)) # exponentiated coefficients

predict(simple_logit_model, type="response") # predicted values
residuals(simple_logit_model, type="deviance") # residuals

anova(model_glm, simple_logit_model, test="Chisq")

---
title: "Part1 Cours ESILV"
author: "Thomas & Bernie"
date: "17/09/2020"
output:
  html_document:
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




# Les librairies utiles & les données
## Introduction
Les institutions financières subissent des pertes importantes en raison du défaut de prêts automobiles. Cela a conduit à un resserrement de la souscription de crédits automobiles et à une augmentation des taux de rejet de crédits automobiles. La nécessité d'un meilleur modèle de notation du risque de crédit est par conséquent soulevé par la directions de l'institutions "SuperCar4Everyone". Cela justifie une étude pour estimer les drivers ou variables prédictrices du défaut de crédit automobile. 

"SuperCar4Everyone" vous a donc embauché pour prédire avec précision la probabilité de défaut de l'emprunteur sur un prêt de véhicule dans le premier EMI (Equated Monthly Versements). l'EMI correspond à est un montant de paiement fixe effectué par un emprunteur à un prêteur à une date précise chaque mois civil. Des versements mensuels égaux sont utilisés pour rembourser les intérêts et le principal chaque mois, de sorte que sur un certain nombre d'années, le prêt soit remboursé intégralement. 

Les informations suivantes concernant le prêt et le prêteur sont fournies:

- Informations sur le prêteur (données démographiques telles que l'âge, le revenu, la preuve d'identité, etc.)
- Informations sur le prêt (détails du décaissement, montant, IME, ratio prêt / valeur, etc.)
- Données et historique du bureau (score du bureau, nombre de comptes actifs, statut des autres prêts, historique de crédit, etc.)

Cela garantira que les clients capables de rembourser ne seront pas rejetés et que des critères discriminants pourront être identifiés et pourront être utilisés par "SuperCar4Everyone" pour minimiser les taux de défaut.


## Les librairies
```{r credit, echo=TRUE,  message=FALSE, warning=FALSE}
# load useful libraries
library(tidyverse)
library(dplyr)
library(knitr)
library(skimr)
library(lubridate)
library(gridExtra)
library(scorecard)
library(ggplot2)
library(ggplotify)
library(plotly)
library(questionr)
library(caret)
library(pROC)
library(purrr)
```


## Les Datas

L’entreprise « SuperCar4Everyone » malgré leur système de données logé dans le cloud nous met à disposition la forme la plus évoluée de stockage de données. Ce CSV contient un certain nombre d’informations et un expert métier est là pour répondre à vos questions.

Contenu du fichier CSV:

- Primary accounts are those which the customer has taken for his personal use
- Secondary accounts are those which the customer act as a co-applicant or gaurantor

```{r credit1, echo=FALSE,  message=FALSE, warning=FALSE, layout="l-body-outset"}
#make the working directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
datainput = read_delim('./data/data_dictionary.csv', col_names = TRUE, delim = ',')
kable(datainput)
```



# Le snorkeling

## Chargement des fichiers et premières impressions

```{r credit2, echo=TRUE,  message=FALSE, warning=FALSE, layout="l-body-outset"}
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
datainput = read_delim('./data/trainRed.csv', col_names = TRUE, delim = ',')
skim(datainput)
```

La préhension de la data via la fonction ‘skim’ est déjà un bon début car il nous donne l’idée de la population des contrats à étudier `r nrow(datainput)` et de l'interprétation des variables en 'character' ou 'numeric'. Elle nous indique les valeurs manquantes et le poid de ces 'n_missing'.

Le format de certaines variables nécessite d’être retravaillé, une rapide vue des variable permet de se faire une première idée de l’état de l’art. 

```{r credit3, echo=TRUE,  message=FALSE, warning=FALSE, layout="l-body-outset"}
kable(head(datainput%>%
  select (ltv,
          disbursed_amount,
          Date.of.Birth,
          supplier_id,
          Employment.Type,
          PERFORM_CNS.SCORE,
          PERFORM_CNS.SCORE.DESCRIPTION,
          loan_default,
          AVERAGE.ACCT.AGE,
          CREDIT.HISTORY.LENGTH)))
```

## Echange avec les métiers
les étudiant doivent maintenant lire les descriptions des variables présentes, regarder les distributions et les premières valeurs et faire poser des questions aux métiers pour une près sélection des variables et une étape de wrangling.




# Deep dive

## Wrangling et mise en forme
Dans un premier temps le re-typage des variables est nécessaire, certains ID peuvent être interprétés comme des valeurs numériques alors qu’elles sont des modalités, le principe est le même pour les booléens ou les modalités.

```{r credit4, echo=TRUE,  message=FALSE, warning=FALSE, layout="l-body-outset"}
dataWrangled <- datainput  %>%
  mutate(Employment.Type = replace_na(datainput$Employment.Type, "None")) %>%
  mutate(State_ID =  as.factor(State_ID)) %>%
  mutate(branch_id =  as.factor(branch_id)) %>%
  mutate(loan_default =  as.factor(loan_default)) %>%
  mutate(VoterID_flag =  as.factor(VoterID_flag)) %>%
  mutate(supplier_id =  as.factor(supplier_id)) %>%
  mutate(manufacturer_id =  as.factor(manufacturer_id)) %>%
  mutate(Current_pincode_ID =  as.factor(Current_pincode_ID)) %>%
  mutate(Employee_code_ID =  as.factor(Employee_code_ID)) %>%
  mutate(MobileNo_Avl_Flag =  as.factor(MobileNo_Avl_Flag)) %>%
  mutate(Aadhar_flag =  as.factor(Aadhar_flag)) %>%
  mutate(PAN_flag =  as.factor(PAN_flag)) %>%
  mutate(Driving_flag =  as.factor(Driving_flag)) %>%
  mutate(Passport_flag =  as.factor(Passport_flag)) 
```

Des modalités trop fragmentées sont difficilement interprétables par les métiers et n’apportent pas vraiment de plus-value métier. Un regroupement plus macro est souvent nécessaire.

Pour pouvoir interpréter le regroupement on peut passer du tableau en effectifs au tableau en pourcentages ligne ou colonne. Pour cela, on peut utiliser les fonctions <span style="color: pink;">lprop</span> de l’extension questionr, qu’on applique à la donnée .

Pour calculer les pourcentages ligne :
```{r credit5, echo=TRUE,  message=FALSE, warning=FALSE, layout="l-body-outset"}
summary(as.factor(dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION))

dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION[dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION %in% 
  c("C-Very Low Risk", "A-Very Low Risk", "B-Very Low Risk","D-Very Low Risk","F-Low Risk","E-Low Risk","G-Low Risk")] <- "Low"
dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION[dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION %in% 
  c("H-Medium Risk", "I-Medium Risk")] <- "Medium"
dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION[dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION %in% 
  c("J-High Risk", "K-High Risk","L-Very High Risk", "M-Very High Risk")] <- "High"
dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION[dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION %in% 
  c("Not Scored: More than 50 active Accounts found", 
    "Not Scored: Only a Guarantor",
    "Not Scored: Not Enough Info available on the customer",
    "Not Scored: No Activity seen on the customer (Inactive)",
    "Not Scored: No Updates available in last 36 months",
    "Not Scored: Sufficient History Not Available",
    "No Bureau History Available")] <- "Not Scored"

summary(as.factor(dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION))

######
tcd <- table(datainput$PERFORM_CNS.SCORE.DESCRIPTION, datainput$loan_default)
lprop(tcd)
tcd <- table(dataWrangled$PERFORM_CNS.SCORE.DESCRIPTION, dataWrangled$loan_default)
lprop(tcd)

```

Pour les problèmes plus complexes, les un parsing plus fin est nécessaire pour des données <span style="color: blue;">`r head(datainput$AVERAGE.ACCT.AGE)` </span>, l’utilisation d’une expression régulière peut-être une solution. Ici nous voulons un time span et non une modalité (2yrs 3monts => 27 months). 

```{r credit6, echo=TRUE,  message=FALSE, warning=FALSE, layout="l-body-outset"}
dataWrangled <- dataWrangled %>%
  mutate(AAA = as.integer((as.numeric(str_match_all( datainput$AVERAGE.ACCT.AGE,"\\d+(?=yrs)")) *12 
         + as.numeric(str_match_all( datainput$AVERAGE.ACCT.AGE,"\\d+(?=mon)"))))) %>%
  mutate(CHL = (as.numeric(str_match_all( datainput$CREDIT.HISTORY.LENGTH,"\\d+(?=yrs)")) *12 
         + as.numeric(str_match_all( datainput$CREDIT.HISTORY.LENGTH,"\\d+(?=mon)"))))

kable(head(dataWrangled%>%
  select (AVERAGE.ACCT.AGE,
          AAA,
          CREDIT.HISTORY.LENGTH,
          CHL)))
```

La même question se pose sur les dates, une maturité ou un time span est toujours plus facilement interprétable qu’une date fixe. Elle donne une dimension de temporalité appréciée par les modélisateur et le métier. 

```{r credit7, echo=TRUE,  message=FALSE, warning=FALSE, layout="l-body-outset"}
thisyear = year(Sys.Date())
dataWrangled <- dataWrangled %>%
  mutate(BorrowerAge = thisyear-year(dmy(Date.of.Birth))) 
dataWrangled <- dataWrangled %>%
  mutate(NbrMonthRelation = 12*(thisyear-year(dmy(DisbursalDate)) + month(dmy(DisbursalDate))))

kable(head(dataWrangled%>%
  select (Date.of.Birth,
          BorrowerAge,
          DisbursalDate,
          NbrMonthRelation)))
```

Nous pouvons ainsi regarder les données travaillées

 - pour les variables numériques:

```{r credit8, echo=TRUE,  message=FALSE, warning=FALSE, fig.fullwidth=TRUE,  fig.height= 15, fig.align='center'}
dataWrangled%>%
  select_if(is.numeric) %>%
  gather(cols, value) %>%
  ggplot(aes(x = value)) + geom_histogram() + facet_wrap( .~cols, scales = "free"  ,ncol = 3)
```

 - pour les variables modales:

```{r credit9, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center'}
dataWrangled%>%
  select_if(is.factor) %>%
  gather(cols, value) %>%
  ggplot(aes(x = value)) + geom_histogram(stat = "count") + facet_wrap( .~cols, scales = "free"  ,ncol = 3)
```

## Discussion avec le business

Les modélisateurs doivent revenir avec des questions pour le business et exclure les premières variables


# Selection des drivers pour le modèle

## Analyses univariées

Nous allons étudier une variable souvent révélatrice de la qualité de la saisie de la donnée. L’âge d’un Obligor nous permet souvent de détecter des valeurs fausses ou aberrantes. 

```{r credit10, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center'}
summary(dataWrangled$BorrowerAge)

bx <- boxplot(dataWrangled$BorrowerAge, col = grey(0.8), main = "Age de l'emprunteur", 
  ylab = "Heures")
abline(h = median(dataWrangled$BorrowerAge, na.rm = TRUE), col = "navy", lty = 2)
text(1.35, median(dataWrangled$BorrowerAge, na.rm = TRUE) + 0.15, "Médiane", 
  col = "navy")
Q1 <- quantile(dataWrangled$BorrowerAge, probs = 0.25, na.rm = TRUE)
abline(h = Q1, col = "darkred")
text(1.35, Q1 + 0.15, "Q1 : premier quartile", col = "darkred", 
  lty = 2)
Q3 <- quantile(dataWrangled$BorrowerAge, probs = 0.75, na.rm = TRUE)
abline(h = Q3, col = "darkred")
text(1.35, Q3 + 0.15, "Q3 : troisième quartile", col = "darkred", 
  lty = 2)
arrows(x0 = 0.7, y0 = quantile(dataWrangled$BorrowerAge, probs = 0.75, na.rm = TRUE), 
  x1 = 0.7, y1 = quantile(dataWrangled$BorrowerAge, probs = 0.25, na.rm = TRUE), 
  length = 0.1, code = 3)
text(0.7, Q1 + (Q3 - Q1)/2 + 0.15, "h", pos = 2)
mtext("L'écart inter-quartile h contient 50 % des individus", 
  side = 1)
abline(h = Q1 - 1.5 * (Q3 - Q1), col = "darkgreen")
text(1.35, Q1 - 1.5 * (Q3 - Q1) + 0.15, "Q1 -1.5 h", col = "darkgreen", 
  lty = 2)
abline(h = Q3 + 1.5 * (Q3 - Q1), col = "darkgreen")
text(1.35, Q3 + 1.5 * (Q3 - Q1) + 0.15, "Q3 +1.5 h", col = "darkgreen", 
  lty = 2)

bx <- ggplot2::ggplot(dataWrangled, ggplot2::aes(x=BorrowerAge, color=BorrowerAge)) +
  ggplot2::geom_boxplot() + 
  theme(legend.position = "none")

bxDef <- ggplot2::ggplot(dataWrangled, ggplot2::aes(x=BorrowerAge, y = loan_default)) +
  ggplot2::geom_boxplot() + 
  theme(legend.position = "none")

dpDef <- ggplot(dataWrangled, aes(x=BorrowerAge, y = loan_default )) +
  geom_violin()+
  geom_boxplot(width=0.1)
grid.arrange( bx, bxDef, dpDef ,ncol=2)

```


## Découpe de variables

Le but est de chercher le meilleur découpage numérique afin de trouver la meilleure relation entre les modalités et la variable de résultat.

```{r credit11, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center'}

bins = woebin(dataWrangled[, c('ltv', 
                                   'disbursed_amount',
                                   'asset_cost',
                                   'loan_default',
                                   'PRI.CURRENT.BALANCE',
                                   'SEC.CURRENT.BALANCE',
                                   'CHL',
                                   'AAA',
                                   'PRI.SANCTIONED.AMOUNT',
                                   'PRI.DISBURSED.AMOUNT',
                                   'SEC.DISBURSED.AMOUNT',
                                   'PERFORM_CNS.SCORE.DESCRIPTION',
                                   'PRI.OVERDUE.ACCTS',
                                   'NO.OF_INQUIRIES',
                                   'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',
                                   'PRIMARY.INSTAL.AMT',
                                   'BorrowerAge')], y = 'loan_default',  method="tree")


## Visualize bins
woebin_plot(bins$ltv)$ltv
woebin_plot(bins$disbursed_amount)$disbursed_amount
woebin_plot(bins$PRI.CURRENT.BALANCE)$PRI.CURRENT.BALANCE
woebin_plot(bins$PRI.DISBURSED.AMOUNT)$PRI.DISBURSED.AMOUNT
woebin_plot(bins$PRIMARY.INSTAL.AMT)$PRIMARY.INSTAL.AMT
woebin_plot(bins$BorrowerAge)$BorrowerAge
woebin_plot(bins$AAA)$AAA
woebin_plot(bins$BorrowerAge)$BorrowerAge
woebin_plot(bins$PERFORM_CNS.SCORE.DESCRIPTION)$PERFORM_CNS.SCORE.DESCRIPTION
woebin_plot(bins$PRI.OVERDUE.ACCTS)$PRI.OVERDUE.ACCTS
woebin_plot(bins$DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS)$DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS


dataWrangled = woebin_ply(dataWrangled, bins, to = 'bin')
```

## Les relations entre les variables

### l'IV
nous pouvons calculer l'IV. Classiquement, cela sert de méthode de classement variable et nous permet d'effectuer une sélection de caractéristiques, ce qui est moins exigeant en calcul que les autres méthodes.
```{r credit21, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center'}
df <- data.frame(c("< 0.02", "0.02 - 0.1", "0.1 - 0.3", "0.3 - 0.5", "> 0.5") , c("très faible", "faible", "moyenne", "forte","très forte") )
colnames(df) =  c("IVr","Puissance de la relation")

# apply function to each variable combination
kable( df)
```
```{r credit22, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', out.width= "80%"}
kable( iv(dataWrangled, y = 'loan_default') %>%
  as_tibble() %>%
  mutate( info_value = round(info_value, 3) ) %>%
  arrange( desc(info_value) ), digits = 2)
```

### Les relations avec la variable explicative

Pour ne retenir que les variables pertinantes une analyse de ralation entre les drivers de risque et la variable à expliquer est nécessaire. Le test du Khi2 par exemple permet de savoir si les variables entretiennent une relation, avec un degré de certitude plus ou moins grand.  Par contre, il ne renseigne pas sur la puissance de cette relation. 
Pouvoir quantifier, lors d'une étude, les croisements de variables qui entretiennent les relations les plus intéressantes est appréciable, cela permet d’orienter ses choix et de valider ou d’invalider ses hypothèses de départ. Plus le v de Cramer s’approche de 1, plus l’intensité de la relation est forte.

```{r credit12, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center'}
df <- data.frame(c("<10", ">10 && <20", ">20 && <30", ">30") , c("très faible", "faible", "moyenne", "forte") )
colnames(df) =  c("Valeurs du V de Cramer","Puissance de la relation")

# apply function to each variable combination
kable( df)
```

```{r credit13, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center'}
# function to get chi square p value and Cramers V
fCramerFunction = function(x,y) {
  tbl = dataWrangled %>% slice(1:7000) %>% select(x,y) %>% table()
  chisq_pval = round(chisq.test(tbl)$p.value, 2)
  cramV = round(cramer.v(tbl), 2) 
  data.frame(x, y, chisq_pval, cramV) }

allCombination <- data.frame(X1 = c("loan_default"),
                        X2 = names(dataWrangled))

# apply function to each variable combination
kable( map2_df(allCombination$X1, allCombination$X2, fCramerFunction)%>% arrange( desc(cramV )))
```

### Les relations entre les variables

Dans une régression, la corrélation des drivers est un problème qui survient lorsque certaines variables de prévision du modèle mesurent le même phénomène. Une corrélation entre les drivers prononcée s’avère problématique, car elle peut perturber la valeur des coefficients de régression et les rendre instables et difficiles à interpréter. Ce phénomène de surapprentissage n’est pas souhaitable. 

```{r credit14, echo=TRUE,  message=TRUE, warning=FALSE, fig.align='center'}

features <- c(
"ltv_bin",
"PERFORM_CNS.SCORE.DESCRIPTION_bin",
"disbursed_amount_bin",
"State_ID",
"CHL_bin",
"PRI.OVERDUE.ACCTS_bin",
"NO.OF_INQUIRIES_bin",
"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_bin",
"BorrowerAge_bin")


# create unique combinations of column names
# sorting will help getting a better plot (upper triangular)
df_comb = data.frame(t(combn(sort(c(features,"loan_default")), 2)), stringsAsFactors = F)

# apply function to each variable combination
df_res = purrr::map2_df(df_comb$X1, df_comb$X2, fCramerFunction)

# plot results
df_res %>%
  #ggplot(aes(x,y,fill=chisq_pval))+
  ggplot(aes(x,y,fill=cramV))+
  geom_tile()+
  geom_text(aes(x,y,label=cramV))+
  scale_fill_gradient(low="red", high="yellow")+
  theme_classic()+ theme(axis.text.x = element_text(angle = 60, hjust = 1))


```


# La regression logistique

```{r credit15, echo=TRUE,  message=TRUE, warning=FALSE, fig.align='center'}
#creating indices
trainIndex <- createDataPartition(dataWrangled$loan_default,p=0.75,list=FALSE)

#splitting data into training/testing data using the trainIndex object
training1_TRAIN <- dataWrangled[trainIndex,] #training data (75% of data)
training1_TEST <- dataWrangled[-trainIndex,] #testing data (25% of data)


var_simple_glm = reformulate(termlabels = features, 
                             response = "loan_default")



simple_logit_model = glm(var_simple_glm, data = training1_TRAIN , family = binomial(link = "logit"))



training1_TEST$Score = predict(simple_logit_model, newdata = training1_TEST, type = "response")
test_roc_simple = roc(training1_TEST$loan_default ~ training1_TEST$Score, plot = TRUE, print.auc = TRUE)

summary(simple_logit_model) # display results
```


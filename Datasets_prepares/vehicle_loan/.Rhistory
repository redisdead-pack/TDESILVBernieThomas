trainIndex <- createDataPartition(datainputreduced$loan_default,p=0.2,list=FALSE)
#splitting data into training/testing data using the trainIndex object
training1_TRAIN <- datainputreduced[trainIndex,] #training data (75% of data)
training1_TEST <- datainputreduced[-trainIndex,] #testing data (25% of data)
var_simple_glm = reformulate(termlabels = c("ltv",
#"State_ID",
"branch_id",
"supplier_id",
"Employment.Type",
"VoterID_flag",
"asset_cost",
"SEC.ACTIVE.ACCTS",
"PERFORM_CNS.SCORE.DESCRIPTION",
"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS",
"SEC.NO.OF.ACCTS",
"PRI.CURRENT.BALANCE",
"PRI.ACTIVE.ACCTS",
"NbrYear",
"NbrYearRelation"),
response = "loan_default")
simple_logit_model = glm(var_simple_glm, data = training1_TRAIN , family = binomial(link = "logit"))
training1_TEST$Score = predict(simple_logit_model, newdata = training1_TEST, type = "response")
test_roc_simple = roc(training1_TEST$loan_default ~ training1_TEST$Score, plot = TRUE, print.auc = TRUE)
summary(simple_logit_model) # display results
View(datainput)
View(datainput)
# load useful libraries
library(pacman)
library(tidyverse)
library(skimr)
library(dplyr)
library(caret)
library(pROC)
library(recipes) # could also load the tidymodels package
library(corrplot)
library(lubridate)
library(data.table) # data mgmt
library(gtools) # combination
library(ggplot2) # graphics
library(plotly) # interactive graphics
library(lsr)
library(mltools)
library(labelled)
#seed for replication
set.seed(7)
# set up so that all variables of tibbles are printed
options(dplyr.width = Inf)
#make the working directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
list.files('./data')
datainput = read_delim('./data/train.csv', col_names = TRUE, delim = ',')
colnames <- names(datainput)
#display information
names(datainput)
###--------------------------------------------------------###
###----------------- Analyse of correlation ---------------###
datainputreduced <- datainput  %>%
select (ltv,
NO.OF_INQUIRIES,
Date.of.Birth,
State_ID,
branch_id,
supplier_id,
Employment.Type,
VoterID_flag,
asset_cost,
SEC.ACTIVE.ACCTS,
disbursed_amount,
PERFORM_CNS.SCORE.DESCRIPTION,
DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS,
loan_default,
SEC.NO.OF.ACCTS,
PRI.CURRENT.BALANCE,
PRI.ACTIVE.ACCTS) %>%
mutate(replace_na(datainput$Employment.Type)) %>%
mutate(State_ID =  as.factor(State_ID)) %>%
mutate(branch_id =  as.factor(branch_id)) %>%
mutate(VoterID_flag =  as.factor(VoterID_flag))
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("C-Very Low Risk", "A-Very Low Risk", "B-Very Low Risk","D-Very Low Risk","F-Low Risk","E-Low Risk","G-Low Risk")] <- "Low"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("H-Medium Risk", "I-Medium Risk")] <- "Medium"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("J-High Risk", "K-High Risk","L-Very High Risk", "M-Very High Risk")] <- "High"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("Not Scored: More than 50 active Accounts found", "Not Scored: Only a Guarantor",
"Not Scored: Not Enough Info available on the customer", "Not Scored: No Activity seen on the customer (Inactive)",
"Not Scored: No Updates available in last 36 months", "Not Scored: Sufficient History Not Available",
"No Bureau History Available")] <- "Not Scored"
thisyear = year(Sys.Date())
datainputreduced <- datainputreduced %>%
mutate(NbrYear = thisyear-year(dmy(Date.of.Birth)))
datainputreduced <- datainputreduced %>%
mutate(NbrYearRelation = 12*(thisyear-year(dmy(Date.of.Birth)) + month(dmy(Date.of.Birth))))
partition(skim(datainputreduced))
##Convert as modal
##Analyse univariée
hist(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour",
xlab = "Heures", ylab = "Effectif")
boxplot(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour",
ylab = "Heures")
##split
# Resulting bins have an equal number of observations in each group
datainputreduced[, "wt2"] <- bin_data(datainputreduced$NbrYear, bins=3, binType = "quantile")
#creating indices
trainIndex <- createDataPartition(datainputreduced$loan_default,p=0.2,list=FALSE)
#splitting data into training/testing data using the trainIndex object
training1_TRAIN <- datainputreduced[trainIndex,] #training data (75% of data)
training1_TEST <- datainputreduced[-trainIndex,] #testing data (25% of data)
var_simple_glm = reformulate(termlabels = c("ltv",
#"State_ID",
"branch_id",
"NO.OF_INQUIRIES",
"supplier_id",
"Employment.Type",
"VoterID_flag",
"asset_cost",
"SEC.ACTIVE.ACCTS",
"PERFORM_CNS.SCORE.DESCRIPTION",
"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS",
"SEC.NO.OF.ACCTS",
"PRI.CURRENT.BALANCE",
"PRI.ACTIVE.ACCTS",
"NbrYear",
"NbrYearRelation"),
response = "loan_default")
simple_logit_model = glm(var_simple_glm, data = training1_TRAIN , family = binomial(link = "logit"))
training1_TEST$Score = predict(simple_logit_model, newdata = training1_TEST, type = "response")
test_roc_simple = roc(training1_TEST$loan_default ~ training1_TEST$Score, plot = TRUE, print.auc = TRUE)
summary(simple_logit_model) # display results
# load useful libraries
library(pacman)
library(tidyverse)
library(skimr)
library(dplyr)
library(caret)
library(pROC)
library(recipes) # could also load the tidymodels package
library(corrplot)
library(lubridate)
library(data.table) # data mgmt
library(gtools) # combination
library(ggplot2) # graphics
library(plotly) # interactive graphics
library(lsr)
library(mltools)
library(labelled)
#seed for replication
set.seed(7)
# set up so that all variables of tibbles are printed
options(dplyr.width = Inf)
#make the working directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
list.files('./data')
datainput = read_delim('./data/train.csv', col_names = TRUE, delim = ',')
colnames <- names(datainput)
#display information
names(datainput)
###--------------------------------------------------------###
###----------------- Analyse of correlation ---------------###
datainputreduced <- datainput  %>%
select (ltv,
disbursed_amount,
NO.OF_INQUIRIES,
Date.of.Birth,
State_ID,
branch_id,
supplier_id,
Employment.Type,
VoterID_flag,
asset_cost,
SEC.ACTIVE.ACCTS,
disbursed_amount,
PERFORM_CNS.SCORE.DESCRIPTION,
DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS,
loan_default,
SEC.NO.OF.ACCTS,
PRI.CURRENT.BALANCE,
PRI.ACTIVE.ACCTS) %>%
mutate(replace_na(datainput$Employment.Type)) %>%
mutate(State_ID =  as.factor(State_ID)) %>%
mutate(branch_id =  as.factor(branch_id)) %>%
mutate(VoterID_flag =  as.factor(VoterID_flag))
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("C-Very Low Risk", "A-Very Low Risk", "B-Very Low Risk","D-Very Low Risk","F-Low Risk","E-Low Risk","G-Low Risk")] <- "Low"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("H-Medium Risk", "I-Medium Risk")] <- "Medium"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("J-High Risk", "K-High Risk","L-Very High Risk", "M-Very High Risk")] <- "High"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("Not Scored: More than 50 active Accounts found", "Not Scored: Only a Guarantor",
"Not Scored: Not Enough Info available on the customer", "Not Scored: No Activity seen on the customer (Inactive)",
"Not Scored: No Updates available in last 36 months", "Not Scored: Sufficient History Not Available",
"No Bureau History Available")] <- "Not Scored"
thisyear = year(Sys.Date())
datainputreduced <- datainputreduced %>%
mutate(NbrYear = thisyear-year(dmy(Date.of.Birth)))
datainputreduced <- datainputreduced %>%
mutate(NbrYearRelation = 12*(thisyear-year(dmy(Date.of.Birth)) + month(dmy(Date.of.Birth))))
partition(skim(datainputreduced))
##Convert as modal
##Analyse univariée
hist(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour",
xlab = "Heures", ylab = "Effectif")
boxplot(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour",
ylab = "Heures")
##split
# Resulting bins have an equal number of observations in each group
datainputreduced[, "wt2"] <- bin_data(datainputreduced$NbrYear, bins=3, binType = "quantile")
#creating indices
trainIndex <- createDataPartition(datainputreduced$loan_default,p=0.2,list=FALSE)
#splitting data into training/testing data using the trainIndex object
training1_TRAIN <- datainputreduced[trainIndex,] #training data (75% of data)
training1_TEST <- datainputreduced[-trainIndex,] #testing data (25% of data)
var_simple_glm = reformulate(termlabels = c("ltv",
"State_ID",
"disbursed_amount",
"branch_id",
"NO.OF_INQUIRIES",
"supplier_id",
"Employment.Type",
"VoterID_flag",
"asset_cost",
"SEC.ACTIVE.ACCTS",
"PERFORM_CNS.SCORE.DESCRIPTION",
"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS",
"SEC.NO.OF.ACCTS",
"PRI.CURRENT.BALANCE",
"PRI.ACTIVE.ACCTS",
"NbrYear",
"NbrYearRelation"),
response = "loan_default")
simple_logit_model = glm(var_simple_glm, data = training1_TRAIN , family = binomial(link = "logit"))
training1_TEST$Score = predict(simple_logit_model, newdata = training1_TEST, type = "response")
test_roc_simple = roc(training1_TEST$loan_default ~ training1_TEST$Score, plot = TRUE, print.auc = TRUE)
summary(simple_logit_model) # display results
# load useful libraries
library(pacman)
library(tidyverse)
library(skimr)
library(dplyr)
library(caret)
library(pROC)
library(recipes) # could also load the tidymodels package
library(corrplot)
library(lubridate)
library(data.table) # data mgmt
library(gtools) # combination
library(ggplot2) # graphics
library(plotly) # interactive graphics
library(lsr)
library(mltools)
library(labelled)
#seed for replication
set.seed(7)
# set up so that all variables of tibbles are printed
options(dplyr.width = Inf)
#make the working directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
list.files('./data')
datainput = read_delim('./data/train.csv', col_names = TRUE, delim = ',')
colnames <- names(datainput)
#display information
names(datainput)
###--------------------------------------------------------###
###----------------- Analyse of correlation ---------------###
datainputreduced <- datainput  %>%
select (ltv,
disbursed_amount,
NO.OF_INQUIRIES,
Date.of.Birth,
State_ID,
branch_id,
supplier_id,
Employment.Type,
VoterID_flag,
asset_cost,
SEC.ACTIVE.ACCTS,
disbursed_amount,
PERFORM_CNS.SCORE.DESCRIPTION,
DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS,
loan_default,
SEC.NO.OF.ACCTS,
PRI.CURRENT.BALANCE,
PRI.ACTIVE.ACCTS) %>%
mutate(replace_na(datainput$Employment.Type)) %>%
mutate(State_ID =  as.factor(State_ID)) %>%
mutate(branch_id =  as.factor(branch_id)) %>%
mutate(VoterID_flag =  as.factor(VoterID_flag))
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("C-Very Low Risk", "A-Very Low Risk", "B-Very Low Risk","D-Very Low Risk","F-Low Risk","E-Low Risk","G-Low Risk")] <- "Low"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("H-Medium Risk", "I-Medium Risk")] <- "Medium"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("J-High Risk", "K-High Risk","L-Very High Risk", "M-Very High Risk")] <- "High"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("Not Scored: More than 50 active Accounts found", "Not Scored: Only a Guarantor",
"Not Scored: Not Enough Info available on the customer", "Not Scored: No Activity seen on the customer (Inactive)",
"Not Scored: No Updates available in last 36 months", "Not Scored: Sufficient History Not Available",
"No Bureau History Available")] <- "Not Scored"
thisyear = year(Sys.Date())
datainputreduced <- datainputreduced %>%
mutate(NbrYear = thisyear-year(dmy(Date.of.Birth)))
datainputreduced <- datainputreduced %>%
mutate(NbrYearRelation = 12*(thisyear-year(dmy(Date.of.Birth)) + month(dmy(Date.of.Birth))))
partition(skim(datainputreduced))
##Convert as modal
##Analyse univariée
hist(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour",
xlab = "Heures", ylab = "Effectif")
boxplot(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour",
ylab = "Heures")
##split
# Resulting bins have an equal number of observations in each group
datainputreduced[, "wt2"] <- bin_data(datainputreduced$NbrYear, bins=3, binType = "quantile")
#creating indices
trainIndex <- createDataPartition(datainputreduced$loan_default,p=0.2,list=FALSE)
#splitting data into training/testing data using the trainIndex object
training1_TRAIN <- datainputreduced[trainIndex,] #training data (75% of data)
training1_TEST <- datainputreduced[-trainIndex,] #testing data (25% of data)
var_simple_glm = reformulate(termlabels = c("ltv",
#"State_ID",
"disbursed_amount",
"branch_id",
"NO.OF_INQUIRIES",
"supplier_id",
"Employment.Type",
"VoterID_flag",
"asset_cost",
"SEC.ACTIVE.ACCTS",
"PERFORM_CNS.SCORE.DESCRIPTION",
"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS",
"SEC.NO.OF.ACCTS",
"PRI.CURRENT.BALANCE",
"PRI.ACTIVE.ACCTS",
"NbrYear",
"NbrYearRelation"),
response = "loan_default")
simple_logit_model = glm(var_simple_glm, data = training1_TRAIN , family = binomial(link = "logit"))
training1_TEST$Score = predict(simple_logit_model, newdata = training1_TEST, type = "response")
test_roc_simple = roc(training1_TEST$loan_default ~ training1_TEST$Score, plot = TRUE, print.auc = TRUE)
summary(simple_logit_model) # display results
# load useful libraries
library(pacman)
library(tidyverse)
library(skimr)
library(dplyr)
library(caret)
library(pROC)
library(recipes) # could also load the tidymodels package
library(corrplot)
library(lubridate)
library(data.table) # data mgmt
library(gtools) # combination
library(ggplot2) # graphics
library(plotly) # interactive graphics
library(lsr)
library(mltools)
library(labelled)
#seed for replication
set.seed(7)
# set up so that all variables of tibbles are printed
options(dplyr.width = Inf)
#make the working directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
list.files('./data')
datainput = read_delim('./data/train.csv', col_names = TRUE, delim = ',')
colnames <- names(datainput)
#display information
names(datainput)
###--------------------------------------------------------###
###----------------- Analyse of correlation ---------------###
datainputreduced <- datainput  %>%
select (ltv,
disbursed_amount,
NO.OF_INQUIRIES,
Date.of.Birth,
State_ID,
branch_id,
supplier_id,
Employment.Type,
VoterID_flag,
asset_cost,
SEC.ACTIVE.ACCTS,
disbursed_amount,
PERFORM_CNS.SCORE.DESCRIPTION,
DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS,
loan_default,
SEC.NO.OF.ACCTS,
PRI.CURRENT.BALANCE,
PRI.ACTIVE.ACCTS) %>%
mutate(replace_na(datainput$Employment.Type)) %>%
mutate(State_ID =  as.factor(State_ID)) %>%
mutate(branch_id =  as.factor(branch_id)) %>%
mutate(VoterID_flag =  as.factor(VoterID_flag))
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("C-Very Low Risk", "A-Very Low Risk", "B-Very Low Risk","D-Very Low Risk","F-Low Risk","E-Low Risk","G-Low Risk")] <- "Low"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("H-Medium Risk", "I-Medium Risk")] <- "Medium"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("J-High Risk", "K-High Risk","L-Very High Risk", "M-Very High Risk")] <- "High"
datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION[datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION %in%
c("Not Scored: More than 50 active Accounts found", "Not Scored: Only a Guarantor",
"Not Scored: Not Enough Info available on the customer", "Not Scored: No Activity seen on the customer (Inactive)",
"Not Scored: No Updates available in last 36 months", "Not Scored: Sufficient History Not Available",
"No Bureau History Available")] <- "Not Scored"
thisyear = year(Sys.Date())
datainputreduced <- datainputreduced %>%
mutate(NbrYear = thisyear-year(dmy(Date.of.Birth)))
datainputreduced <- datainputreduced %>%
mutate(NbrYearRelation = 12*(thisyear-year(dmy(Date.of.Birth)) + month(dmy(Date.of.Birth))))
partition(skim(datainputreduced))
##Convert as modal
##Analyse univariée
hist(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour",
xlab = "Heures", ylab = "Effectif")
boxplot(datainputreduced$NbrYear, main = "Nombre d'heures passées devant la télé par jour",
ylab = "Heures")
##split
# Resulting bins have an equal number of observations in each group
datainputreduced[, "wt2"] <- bin_data(datainputreduced$NbrYear, bins=3, binType = "quantile")
#creating indices
trainIndex <- createDataPartition(datainputreduced$loan_default,p=0.3,list=FALSE)
#splitting data into training/testing data using the trainIndex object
training1_TRAIN <- datainputreduced[trainIndex,] #training data (75% of data)
training1_TEST <- datainputreduced[-trainIndex,] #testing data (25% of data)
var_simple_glm = reformulate(termlabels = c("ltv",
#"State_ID",
"disbursed_amount",
"branch_id",
"NO.OF_INQUIRIES",
"supplier_id",
"Employment.Type",
"VoterID_flag",
"asset_cost",
"SEC.ACTIVE.ACCTS",
"PERFORM_CNS.SCORE.DESCRIPTION",
"DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS",
"SEC.NO.OF.ACCTS",
"PRI.CURRENT.BALANCE",
"PRI.ACTIVE.ACCTS",
"NbrYear",
"NbrYearRelation"),
response = "loan_default")
simple_logit_model = glm(var_simple_glm, data = training1_TRAIN , family = binomial(link = "logit"))
training1_TEST$Score = predict(simple_logit_model, newdata = training1_TEST, type = "response")
test_roc_simple = roc(training1_TEST$loan_default ~ training1_TEST$Score, plot = TRUE, print.auc = TRUE)
summary(simple_logit_model) # display results
hist(datainputreduced$NbrYear, main = "Age des clients",
xlab = "Age", ylab = "Effectif")
boxplot(datainputreduced$NbrYear, main = "Age des clients",
ylab = "Age")
library(questionr)
install.packages("questionr")
library(questionr)
table(datainput$PERFORM_CNS.SCORE.DESCRIPTION, datainput$loan_default)
tcd <- table(datainput$PERFORM_CNS.SCORE.DESCRIPTION, datainput$loan_default)
tcd
lprop(tab)
lprop(tcd)
tcd <- table(datainputreduced$PERFORM_CNS.SCORE.DESCRIPTION, datainputreduced$loan_default)
lprop(tcd)
chisq.test(tcd)
chisq.residuals(tcd)
datainputreduced <- datainputreduced  %>%
select (-disbursed_amount) %>%
select (-supplier_id) %>%
select (-asset_cost)
# function to get chi square p value and Cramers V
fCramerFunction = function(x,y) {
tbl = datainputreduced %>% select(x,y) %>% table()
chisq_pval = round(chisq.test(tbl)$p.value, 4)
cramV = round(cramersV(tbl), 4)
data.frame(x, y, chisq_pval, cramV) }
# create unique combinations of column names
# sorting will help getting a better plot (upper triangular)
df_comb = data.frame(t(combn(sort(names(datainputreduced)), 2)), stringsAsFactors = F)
# apply function to each variable combination
df_res = map2_df(df_comb$X1, df_comb$X2, fCramerFunction)
# plot results
df_res %>%
#ggplot(aes(x,y,fill=chisq_pval))+
ggplot(aes(x,y,fill=cramV))+
geom_tile()+
geom_text(aes(x,y,label=cramV))+
scale_fill_gradient(low="red", high="yellow")+
theme_classic()
df_comb = data.frame(t(combn(sort(names(datainputreduced)), 2)), stringsAsFactors = F)
datainputcor <- datainputreduced  %>%
select (
NO.OF_INQUIRIES,
State_ID,
branch_id,
Employment.Type,
SEC.ACTIVE.ACCTS,
PERFORM_CNS.SCORE.DESCRIPTION,
DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS,
loan_default,
SEC.NO.OF.ACCTS,
PRI.CURRENT.BALANCE,
PRI.ACTIVE.ACCTS)
# function to get chi square p value and Cramers V
fCramerFunction = function(x,y) {
tbl = datainputcor %>% select(x,y) %>% table()
chisq_pval = round(chisq.test(tbl)$p.value, 4)
cramV = round(cramersV(tbl), 4)
data.frame(x, y, chisq_pval, cramV) }
# create unique combinations of column names
# sorting will help getting a better plot (upper triangular)
df_comb = data.frame(t(combn(sort(names(datainputcor)), 2)), stringsAsFactors = F)
# apply function to each variable combination
df_res = map2_df(df_comb$X1, df_comb$X2, fCramerFunction)
